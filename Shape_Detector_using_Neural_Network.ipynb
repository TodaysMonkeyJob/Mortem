{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Kursova.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oleg1601/Mortem/blob/master/Shape_Detector_using_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H3ATAdp_URp",
        "colab_type": "text"
      },
      "source": [
        "# Get the Class names "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlx6-LFL_jbi",
        "colab_type": "text"
      },
      "source": [
        "This file contains a subset of the quick draw classes. I choose around 100 classes from the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXv-xzU1sd88",
        "colab_type": "code",
        "outputId": "216b5c63-2eb6-440e-d809-3263e1f34f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget 'https://github.com/oleg1601/Mortem/blob/master/mini_classes_full.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-11 16:08:34--  https://github.com/oleg1601/Mortem/blob/master/mini_classes.txt\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘mini_classes.txt’\n",
            "\n",
            "\rmini_classes.txt        [<=>                 ]       0  --.-KB/s               \rmini_classes.txt        [ <=>                ]  71.69K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-01-11 16:08:34 (2.73 MB/s) - ‘mini_classes.txt’ saved [73412]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GL_TdMffD6-",
        "colab_type": "text"
      },
      "source": [
        "Read the classes names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP-OxOx5sy0b",
        "colab_type": "code",
        "outputId": "1a78c32d-e8ba-4821-9cb6-5ac3f74a1e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f = open(\"mini_classes_full.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = f.readlines()\n",
        "f.close()\n",
        "count = len(classes)\n",
        "print(count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTE6D3uxtMc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NDfBHVjACAt",
        "colab_type": "text"
      },
      "source": [
        "# Download the Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MC_PUS-fKjH",
        "colab_type": "text"
      },
      "source": [
        "Loop over the classes and download the currospondent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdSUnpL0u22Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22DPhL5FtWcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "def download():\n",
        "  \n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5jF6TXXu-Bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEdnbBVXAI-X",
        "colab_type": "text"
      },
      "source": [
        "# Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2FYrPgOKh6t",
        "colab_type": "code",
        "outputId": "ad09aeae-a013-4e8b-f0df-c5e8abeadaf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o30ipBPAQ5Y",
        "colab_type": "text"
      },
      "source": [
        "# Load the Data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBq3GXEKAYuO",
        "colab_type": "text"
      },
      "source": [
        "Each class contains different number samples of arrays stored as .npy format. Since we have some memory limitations we only load 5000 images per class.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HEIgQNHYQnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(root, vfold_ratio=0.05, max_items_per_class= 5000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "    # root -- announces the name of the folder, where our classes save\n",
        "    # vfold_ratio -- define in percent how many items from one class distribute for test, in our way it is 20% \n",
        "    # max_items_per_class -- number of elements which we take from one class\n",
        "    # glob.glob -- return a possibly-empty list of path names that match pathname, which must be a string containing a path specification.\n",
        "    # in our code we return pathway as os.path.join(folder's name; and add to it .npy to define it as numpy model)\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784]) # np.empty for X -- define empty array to store multi-dimensional data where \n",
        "                           # 784 count of pixel number in our pictures to order in memory.\n",
        "    y = np.empty([0])      # np.empty for Y -- define empty array to store sequence number of pictures from class\n",
        "    class_names = []       # define empty array to store class names from data\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):     # define each file from data\n",
        "        data = np.load(file)                   # initialise load files\n",
        "        data = data[0: max_items_per_class, :] # load files from 0 to max_items_per_class, colon -- means all file in list\n",
        "        labels = np.full(data.shape[0], idx)   # np.full -- return a new array of given shape. \n",
        "                                               # The shape attribute for numpy arrays returns the dimensions of the array. \n",
        "                                               # If data has n rows and m columns, then data.shape is (n,m). So data.shape[0] is n.\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)  # Join a sequence of arrays along an existing axis\n",
        "        y = np.append(y, labels)               # np.append -- function is used to merge two arrays. \n",
        "                                               # This function returns a new array and the original array remains unchanged.\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file)) \n",
        "        # Split the pathname path into a pair (root, ext) such that root + ext == path,\n",
        "        # and ext is empty or begins with a period and contains at most one period.\n",
        "        class_names.append(class_name) \n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0]) \n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100)) \n",
        "\n",
        "    x_test = x[0:vfold_size, :] # allocate files from 0 to vfold_size for testing, colon -- means all file in list\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :] # allocate others files for training \n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6uUjN-WL2Y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data') # load requable files\n",
        "num_classes = len(class_names) # count element for neural network\n",
        "image_size = 28 # define size of image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhGEDS0SMgLK",
        "colab_type": "code",
        "outputId": "2051fadd-bb8e-414f-977f-2092a650356d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "370500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNZmQvBWBBHE",
        "colab_type": "text"
      },
      "source": [
        "Show some random data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfpDaHRkyMQC",
        "colab_type": "code",
        "outputId": "d3735612-3c58-4c49-dc7c-c390ca68cf97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "brain\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8InHz5NBFrV",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess the Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2GHUq7D2r9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "# pre-proces the data by ensuring the image are of shape 28*28*1 and converting the pixels into a float type variable for training\n",
        "\n",
        "x_train /= 255.0 # x_train =np.interp(x_train, [0, 255], [0, 1]) -- alternatile form\n",
        "                 # in other word it is simpe interpolation for pixel scaling\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "# we convert the class labels to one hot for trainig\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL6XAb4hBMSc",
        "colab_type": "text"
      },
      "source": [
        "# The Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYUVV2wf2z8H",
        "colab_type": "code",
        "outputId": "93ff904d-5092-4557-b4e0-358847aab866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "# Define model with 9 layers\n",
        "model = keras.Sequential() # Define type of model anfd start add layers\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(128, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(256, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(345, activation='softmax')) \n",
        "# Initialize model\n",
        "Nadam = tf.keras.optimizers.Nadam()\n",
        "#adam = tf.keras.train.Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Nadam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_30 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 256)               590080    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 78)                20046     \n",
            "=================================================================\n",
            "Total params: 979,790\n",
            "Trainable params: 979,790\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YRSRkOyBP1P",
        "colab_type": "text"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OMEJ7kF3lsP",
        "colab_type": "code",
        "outputId": "1a7b4cab-7096-419b-86ee-faa8ec48f66d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.01, batch_size=258, verbose=2, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 366795 samples, validate on 3705 samples\n",
            "Epoch 1/5\n",
            "366795/366795 - 19s - loss: 1.3411 - top_k_categorical_accuracy: 0.8669 - val_loss: 0.9186 - val_top_k_categorical_accuracy: 0.9309\n",
            "Epoch 2/5\n",
            "366795/366795 - 18s - loss: 0.8194 - top_k_categorical_accuracy: 0.9368 - val_loss: 0.7793 - val_top_k_categorical_accuracy: 0.9404\n",
            "Epoch 3/5\n",
            "366795/366795 - 18s - loss: 0.6920 - top_k_categorical_accuracy: 0.9488 - val_loss: 0.7242 - val_top_k_categorical_accuracy: 0.9417\n",
            "Epoch 4/5\n",
            "366795/366795 - 18s - loss: 0.6104 - top_k_categorical_accuracy: 0.9562 - val_loss: 0.7184 - val_top_k_categorical_accuracy: 0.9447\n",
            "Epoch 5/5\n",
            "366795/366795 - 18s - loss: 0.5431 - top_k_categorical_accuracy: 0.9622 - val_loss: 0.7249 - val_top_k_categorical_accuracy: 0.9417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f79ff96a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2KztY7qEn9_",
        "colab_type": "text"
      },
      "source": [
        "# Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssaZczS7DxeA",
        "colab_type": "code",
        "outputId": "fa5f2d47-bed3-4b80-f4c0-9f5bd4d37902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuarcy: 94.11%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xBM_w0VBbNr",
        "colab_type": "text"
      },
      "source": [
        "# Inference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADPlAas8kU4R",
        "colab_type": "code",
        "outputId": "c3118962-cddd-4854-b464-aeab7b0ceabb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx] ######## Check it with screenshots\n",
        "#plt.subplot(2,2,1)  # Building Space for Image\n",
        "plt.imshow(img.squeeze())\n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "indicator = (-pred).argsort()[:5]\n",
        "latex = [class_names[x] for x in indicator] # Possible Variants\n",
        "indicator.sort() # Sort value of indicator\n",
        "new_ind = indicator[::-1] # Making reverse values of indicator\n",
        "print(latex)\n",
        "print(new_ind)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['carrot', 'paintbrush', 'asparagus', 'toothbrush', 'crayon']\n",
            "[197 154  97  96  20]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYQeCIOxAEIQdCIKwA0EQdiAIwg4E8X9q2l60ByWgUwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyol_bTblanw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plt.subplot(2,1,2)  # Building Space for Diagram\n",
        "plot = plt.bar(latex, new_ind, color = \"darkblue\", alpha=0.8, width=0.7) \n",
        "# Initialize diagram with possible variants of our image\n",
        "plot[0].set_color('r') # Draw Max point in Red colour\n",
        "for value in plot: # Initialize for writing indicatour value in the top of bar \n",
        "    height = value.get_height()- 257\n",
        "    plt.text(value.get_x() + value.get_width()/2.0,\n",
        "             2.002*height,'%d' % int(height + 257), ha='center', va='bottom')\n",
        "plt.title('Possible Prediction')\n",
        "plt.xlabel('Variants')\n",
        "plt.ylabel('Percent value')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPp5D82YBhM-",
        "colab_type": "text"
      },
      "source": [
        "# Store the classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoFI1msFYpCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfJ6dpaDBpRx",
        "colab_type": "text"
      },
      "source": [
        "# Install TensorFlowJS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJJDfp9mY9Xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflowjs "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oBl0ZKVB00d",
        "colab_type": "text"
      },
      "source": [
        "# Save and Convert "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVICB3TbZGb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTWWlGdWZOvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKYxE2MEB6LV",
        "colab_type": "text"
      },
      "source": [
        "# Zip and Download "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "865-t79uaB63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp class_names.txt model/class_names.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLC-MzW8ZXTa",
        "colab_type": "code",
        "outputId": "4aa03697-cd9d-4111-cea6-7b69d61515e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!zip -r model.zip model "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model/ (stored 0%)\n",
            "  adding: model/group1-shard1of1.bin (deflated 7%)\n",
            "  adding: model/model.json (deflated 82%)\n",
            "  adding: model/class_names.txt (deflated 43%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vfPR03xZZeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}